{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Compute\n",
    "\n",
    "When you run a script as an Azure Machine Learning experiment, you need to define the execution context for the experiment run. The execution context is made up of:\n",
    "\n",
    "* The Python environment for the script, which must include all Python packages used in the script.\n",
    "* The compute target on which the script will be run. This could be the local workstation from which the experiment run is initiated, or a remote compute target such as a training cluster that is provisioned on-demand.\n",
    "\n",
    "In this lab, you'll explore *environments* and *compute targets* for experiments.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./config.json\n",
      "Overriding of current TracerProvider is not allowed\n",
      "Overriding of current LoggerProvider is not allowed\n",
      "Overriding of current MeterProvider is not allowed\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n",
      "Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Configure the MLClient\n",
    "# The following example uses default authentication, or loads config from a config.json file\n",
    "try:\n",
    "    ml_client = MLClient.from_config(credential\n",
    "                                     =DefaultAzureCredential())\n",
    "except Exception as ex:\n",
    "    # If no config.json found, provide details manually\n",
    "    subscription_id = \"<YOUR_SUBSCRIPTION_ID>\"\n",
    "    resource_group = \"<YOUR_RESOURCE_GROUP>\"\n",
    "    workspace_name = \"<YOUR_WORKSPACE_NAME>\"\n",
    "    ml_client = MLClient(DefaultAzureCredential(), subscription_id, resource_group, workspace_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazureml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazureml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Workspace\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Load the workspace from the saved config file\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'azureml.core'"
     ]
    }
   ],
   "source": [
    "# import azureml.core\n",
    "# from azureml.core import Workspace\n",
    "\n",
    "# # Load the workspace from the saved config file\n",
    "# ws = Workspace.from_config()\n",
    "# print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "In this lab, you'll use a dataset containing details of diabetes patients. Run the cell below to create this dataset (if you already created it in a previous lab, the code will find the existing version.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-ml in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (1.30.0)\n",
      "Requirement already satisfied: azure-identity in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (1.25.1)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.1.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (6.0.2)\n",
      "Requirement already satisfied: azure-core>=1.23.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (1.37.0)\n",
      "Requirement already satisfied: azure-mgmt-core>=1.3.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (1.6.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (3.26.1)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (4.25.1)\n",
      "Requirement already satisfied: tqdm<5.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (4.67.1)\n",
      "Requirement already satisfied: strictyaml<2.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (1.7.3)\n",
      "Requirement already satisfied: colorama<1.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (0.4.6)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (2.10.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (12.19.0)\n",
      "Requirement already satisfied: azure-storage-file-share in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (12.23.1)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.2.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (12.22.0)\n",
      "Requirement already satisfied: pydash<9.0.0,>=6.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (8.0.5)\n",
      "Requirement already satisfied: isodate<1.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (0.7.2)\n",
      "Requirement already satisfied: azure-common>=1.1 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (1.1.28)\n",
      "Requirement already satisfied: typing-extensions<5.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (4.14.1)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-ai-ml) (1.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.0.0->azure-ai-ml) (0.27.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from marshmallow<4.0.0,>=3.5->azure-ai-ml) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from strictyaml<2.0.0->azure-ai-ml) (2.9.0.post0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-identity) (45.0.7)\n",
      "Requirement already satisfied: msal>=1.30.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-identity) (1.34.0)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: requests>=2.21.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-core>=1.23.0->azure-ai-ml) (2.32.5)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-ml)\n",
      "  Using cached azure_storage_blob-12.27.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from cryptography>=2.5->azure-identity) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from cffi>=1.14->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from requests>=2.21.0->azure-core>=1.23.0->azure-ai-ml) (2025.8.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from python-dateutil>=2.6.0->strictyaml<2.0.0->azure-ai-ml) (1.17.0)\n",
      "Requirement already satisfied: azure-core-tracing-opentelemetry~=1.0.0b11 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b12)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter~=1.0.0b46 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.0.0b46)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.39 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-django==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-flask==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-psycopg2==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-requests==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-urllib3==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-resource-detector-azure<1.0.0,>=0.1.5 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry->azure-ai-ml) (0.1.5)\n",
      "Requirement already satisfied: opentelemetry-api~=1.12 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (1.39.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-wsgi==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation==0.60b0->opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (1.17.3)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-fastapi==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: asgiref~=3.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-asgi==0.60b0->opentelemetry-instrumentation-fastapi==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (3.11.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-dbapi==0.60b0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-instrumentation-psycopg2==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (0.60b0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from opentelemetry-api~=1.12->opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (8.7.0)\n",
      "Requirement already satisfied: msrest>=0.6.10 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b46->azure-monitor-opentelemetry->azure-ai-ml) (0.7.1)\n",
      "Requirement already satisfied: psutil<8,>=5.9 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from azure-monitor-opentelemetry-exporter~=1.0.0b46->azure-monitor-opentelemetry->azure-ai-ml) (7.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api~=1.12->opentelemetry-instrumentation-django==0.60b0->azure-monitor-opentelemetry->azure-ai-ml) (3.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from msrest>=0.6.10->azure-monitor-opentelemetry-exporter~=1.0.0b46->azure-monitor-opentelemetry->azure-ai-ml) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.10->azure-monitor-opentelemetry-exporter~=1.0.0b46->azure-monitor-opentelemetry->azure-ai-ml) (3.3.1)\n",
      "Using cached azure_storage_blob-12.27.1-py3-none-any.whl (428 kB)\n",
      "Installing collected packages: azure-storage-blob\n",
      "  Attempting uninstall: azure-storage-blob\n",
      "    Found existing installation: azure-storage-blob 12.19.0\n",
      "    Uninstalling azure-storage-blob-12.19.0:\n",
      "      Successfully uninstalled azure-storage-blob-12.19.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "azureml-mlflow 1.60.0 requires azure-storage-blob<=12.19.0,>=12.5.0, but you have azure-storage-blob 12.27.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed azure-storage-blob-12.27.1\n"
     ]
    }
   ],
   "source": [
    "!pip install azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering new dataset 'diabetes-v2-dataset' version 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading data (0.82 MBs): 100%|██████████| 820137/820137 [00:00<00:00, 1780823.16it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset registered and uploaded.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "import os\n",
    "\n",
    "# --- V2 Data Asset Creation ---\n",
    "\n",
    "data_name = 'diabetes-v2-dataset'\n",
    "data_version = '1'\n",
    "\n",
    "# The v2 SDK expects a path (local path to upload from, or cloud path)\n",
    "# Assuming your data files are in a local directory named './data/'\n",
    "# The SDK handles the upload to the default datastore when you create the data asset\n",
    "my_data = Data(\n",
    "    name=data_name,\n",
    "    version=data_version,\n",
    "    description=\"Diabetes data (v2)\",\n",
    "    path=\"./data/\", # This path will be uploaded to the default datastore\n",
    "    type=AssetTypes.URI_FOLDER, # Use URI_FOLDER for a directory of files\n",
    ")\n",
    "\n",
    "# Check if the data asset already exists\n",
    "try:\n",
    "    existing_data = ml_client.data.get(name=data_name, version=data_version)\n",
    "    print(f\"Dataset '{data_name}' version {data_version} already registered.\")\n",
    "    # If you want to force creation of a new version, update 'data_version' above\n",
    "\n",
    "except Exception:\n",
    "    # If it doesn't exist, create it (this uploads the data)\n",
    "    print(f\"Registering new dataset '{data_name}' version {data_version}...\")\n",
    "    # The create command uploads the local data to the default datastore\n",
    "    ml_client.data.create_or_update(my_data)\n",
    "    print(\"Dataset registered and uploaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD VERSION\n",
    "# \n",
    "# from azureml.core import Dataset\n",
    "\n",
    "# default_ds = ws.get_default_datastore()\n",
    "\n",
    "# if 'diabetes dataset' not in ws.datasets:\n",
    "#     default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "#                         target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "#                         overwrite=True, # Replace existing files of the same name\n",
    "#                         show_progress=True)\n",
    "\n",
    "#     #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "#     tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "#     # Register the tabular dataset\n",
    "#     try:\n",
    "#         tab_data_set = tab_data_set.register(workspace=ws, \n",
    "#                                 name='diabetes dataset',\n",
    "#                                 description='diabetes data',\n",
    "#                                 tags = {'format':'CSV'},\n",
    "#                                 create_new_version=True)\n",
    "#         print('Dataset registered.')\n",
    "#     except Exception as ex:\n",
    "#         print(ex)\n",
    "# else:\n",
    "#     print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training Script\n",
    "\n",
    "Run the following two cells to create:\n",
    "1. A folder for a new experiment\n",
    "2. An training script file that uses **scikit-learn** to train a model and **matplotlib** to plot a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_training_logistic folder created\n"
     ]
    }
   ],
   "source": [
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'diabetes_training_logistic'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# import os\n",
    "import argparse\n",
    "# from azureml.core import Run ## OLD!\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--regularization REG_RATE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/augustvollbrecht/Library/Jupyter/runtime/kernel-v3c14c1441021eea83e556ee0f95bc44176dbf1eea.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/augustvollbrecht/virtual/new_dsb/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# %%writefile $experiment_folder/diabetes_training.py\n",
    "#  Set regularization hyperparameter (passed as an argument to the script)\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01, help='regularization rate')\n",
    "args = parser.parse_args()\n",
    "reg = args.reg_rate\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the diabetes data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['diabetes'].to_pandas_dataframe()\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run ID: None\n"
     ]
    }
   ],
   "source": [
    "# Get the run ID from environment variables\n",
    "run_id = os.environ.get('AZUREML_RUN_ID')\n",
    "\n",
    "# Use azureml-events for logging (optional, but standard for v2)\n",
    "# from azureml.events import log_metric\n",
    "# log_metric(\"my_metric\", 0.9)\n",
    "\n",
    "print(f\"Current run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an Environment\n",
    "\n",
    "When you run a Python script as an experiment in Azure Machine Learning, a Conda environment is created to define the execution context for the script. Azure Machine Learning provides a default environment that includes many common packages; including the **azureml-defaults** package that contains the libraries necessary for working with an experiment run, as well as popular packages like **pandas** and **numpy**.\n",
    "\n",
    "You can also define your own environment and add packages by using **conda** or **pip**, to ensure your experiment has access to all the libraries it requires. \n",
    "\n",
    "Run the following cell to create an environment for the diabetes experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'azureml.core'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazureml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Environment\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazureml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconda_dependencies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CondaDependencies\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a Python environment for the experiment\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'azureml.core'"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-experiment-env\")\n",
    "diabetes_env.python.user_managed_dependencies = False # Let Azure ML manage dependencies\n",
    "diabetes_env.docker.enabled = True # Use a docker container\n",
    "\n",
    "# Create a set of package dependencies (conda or pip as required)\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn'],\n",
    "                                          pip_packages=['azureml-defaults', 'azureml-dataprep[pandas]'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "print(diabetes_env.name, 'defined.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the environment for the experiment by assigning it to an Estimator (or RunConfig).\n",
    "\n",
    "The following code assigns the environment you created to a generic estimator, and submits an experiment. As the experiment runs, observe the run details in the widget and in the **azureml_logs/60_control_log.txt** output log, you'll see the conda environment being built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      inputs=[diabetes_ds.as_named_input('diabetes')],\n",
    "                      script_params=script_params,\n",
    "                      compute_target = 'local',\n",
    "                      environment_definition = diabetes_env,\n",
    "                      entry_script='diabetes_training.py')\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training')\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment successfully used the environment, which included all of the packages it required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having gone to the trouble of defining an environment with the packages you need, you can register it in the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment\n",
    "diabetes_env.register(workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an Experiment on a Remote Compute Target\n",
    "\n",
    "In many cases, your local compute resources may not be sufficient to process a complex or long-running experiment that needs to process a large volume of data; and you may want to take advantage of the ability to dynamically create and use compute resources in the cloud.\n",
    "\n",
    "Azure ML supports a range of compute targets, which you can define in your workpace and use to run experiments; paying for the resources only when using them. In this case, we'll run the diabetes training experiment on a compute cluster with a unique name of your choosing, so let's verify that exists (and if not, create it) so we can use it to run training experiments.\n",
    "\n",
    "> **Important**: Change *your-compute-cluster* to a unique name for your compute cluster in the code below before running it! Cluster names must be globally unique names between 2 to 16 characters in length. Valid characters are letters, digits, and the - character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you're ready to run the experiment on the compute you created. You can do this by specifying the **compute_target** parameter in the estimator (you can set this to either the name of the compute target, or a **ComputeTarget** object.)\n",
    "\n",
    "You'll also reuse the environment you registered previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core import Environment, Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Get the environment\n",
    "registered_env = Environment.get(ws, 'diabetes-experiment-env')\n",
    "\n",
    "# Set the script parameters\n",
    "script_params = {\n",
    "    '--regularization': 0.1\n",
    "}\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create an estimator\n",
    "estimator = Estimator(source_directory=experiment_folder,\n",
    "                      inputs=[diabetes_ds.as_named_input('diabetes')],\n",
    "                      script_params=script_params,\n",
    "                      compute_target = cluster_name, # Run the experiment on the remote compute target\n",
    "                      environment_definition = registered_env,\n",
    "                      entry_script='diabetes_training.py')\n",
    "\n",
    "# Create an experiment\n",
    "experiment = Experiment(workspace = ws, name = 'diabetes-training')\n",
    "\n",
    "# Run the experiment\n",
    "run = experiment.submit(config=estimator)\n",
    "# Show the run details while running\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The experiment will take quite a lot longer because a container image must be built with the conda environment, and then the cluster nodes must be started and the image deployed before the script can be run. For a simple experiment like the diabetes training script, this may seem inefficient; but imagine you needed to run a more complex experiment with a large volume of data that would take several hours on your local workstation - dynamically creating more scalable compute may reduce the overall time significantly.\n",
    "\n",
    "While you're waiting for the experiment to run, you can check on the status of the compute in the widget above or in [Azure Machine Learning studio](https://ml.azure.com).\n",
    "\n",
    "> **Note**: After some time, the widget may stop updating. You'll be able to tell the experiment run has completed by the information displayed immediately below the widget and by the fact that the kernel indicator at the top right of the notebook window has changed from  **&#9899;** (indicating the kernel is running code) to **&#9711;** (indicating the kernel is idle).\n",
    "\n",
    "After the experiment has finished, you can get the metrics and files generated by the experiment run. The files will include logs for building the image and managing the compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logged metrics\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More Information**:\n",
    "\n",
    "- For more information about environments in Azure Machine Learning, see [Reuse environments for training and deployment by using Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/how-to-use-environments).\n",
    "- For more information about compute targets in Azure Machine Learning, see [What are compute targets in Azure Machine Learning?](https://docs.microsoft.com/azure/machine-learning/concept-compute-target)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_dsb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
